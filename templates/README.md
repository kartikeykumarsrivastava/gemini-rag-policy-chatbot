

# ğŸ“˜ **Gemini RAG Policy Chatbot**

A **secure, enterprise-grade AI assistant** that answers questions on company policy documents using **Google Gemini**, **RAG (Retrieval-Augmented Generation)**, **FAISS**, **Flask**, **JWT**, and **HashiCorp Vault**.

This project demonstrates how large organizations can safely use LLMs **without exposing confidential data**.

---

## ğŸ§  What This System Does

* Reads multiple company policy PDFs
* Converts them into searchable embeddings
* Retrieves only the relevant chunks for each question
* Uses Gemini LLM to generate grounded answers
* Protects secrets using Vault
* Secures access using JWT

No documents are ever sent to Gemini in full.
No data is stored or trained by the LLM.

---

## ğŸ— Architecture

![Architecture](architecture.png)

*(Use the architecture diagram you generated here)*

---

## ğŸ”„ How It Works (Interactive Flow)

```
1. User logs in â†’ receives JWT token
2. User asks a question
3. Flask validates JWT
4. Query â†’ Vector Search (FAISS)
5. Relevant document chunks retrieved
6. Gemini API key fetched from Vault
7. Gemini receives:
      - User question
      - Retrieved policy chunks
8. Gemini generates answer
9. Response returned to user
```

---

## ğŸ” Security Model

| Layer       | Protection                                  |
| ----------- | ------------------------------------------- |
| JWT         | Only authenticated users can query          |
| Vault       | Gemini API key is encrypted & never in code |
| RAG         | Gemini never sees full documents            |
| FAISS       | Company data stored locally                 |
| No training | Gemini does not learn your data             |
| Audit-ready | All access can be logged                    |

This follows the same model used by:

* Microsoft Copilot
* Google Vertex AI
* Salesforce Einstein
* Enterprise AI copilots

---

## ğŸ“‚ Project Structure

```
rag_gemini_chatbot/
â”‚
â”œâ”€â”€ app.py                # Flask API + UI
â”œâ”€â”€ rag_chat.py           # RAG orchestration
â”œâ”€â”€ vector_store.py       # FAISS + embeddings
â”œâ”€â”€ ingest.py             # PDF loading & chunking
â”œâ”€â”€ vault_client.py       # Secure secret retrieval
â”œâ”€â”€ documents/            # Company PDFs
â”‚     â””â”€â”€ policy.pdf
â”œâ”€â”€ templates/
â”‚     â””â”€â”€ chat.html       # Web UI
â”œâ”€â”€ static/
â”‚     â””â”€â”€ style.css
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```

---

## ğŸš€ How to Run

### 1ï¸âƒ£ Start Vault

```bash
vault server -dev
export VAULT_ADDR="http://127.0.0.1:8200"
export VAULT_TOKEN="s.xxxxx"
vault kv put secret/gemini api_key="YOUR_GEMINI_KEY"
```

---

### 2ï¸âƒ£ Install dependencies

```bash
pip install flask google-genai faiss-cpu pypdf numpy hvac flask-jwt-extended
```

---

### 3ï¸âƒ£ Build vector database

```bash
python -c "from ingest import load_all_pdfs, chunk_text; from vector_store import create_vector_db; text=load_all_pdfs(); chunks=chunk_text(text); create_vector_db(chunks)"
```

---

### 4ï¸âƒ£ Run application

```bash
python app.py
```

Open:

```
http://localhost:8000
```

Login:

```
admin / admin123
```

---

## ğŸ³ Docker Support

```bash
docker build -t gemini-rag .
docker run -p 8000:8000 gemini-rag
```

---

## ğŸ§© Why This Matters

This project demonstrates:

> **How to use LLMs in a bank, enterprise, or government environment without leaking data**

It solves:

* Data privacy
* Compliance
* Security
* Vendor lock-in
* Hallucinations

Using:

* RAG
* Vault
* JWT
* Vector databases

---

## ğŸ† Use Cases

* HR Policy Assistant
* Legal Contract Chatbot
* Banking Policy Copilot
* Insurance Guidelines Bot
* Compliance Knowledge Base

---


